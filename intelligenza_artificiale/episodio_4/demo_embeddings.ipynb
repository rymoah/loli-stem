{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "48OUgKi-hTEJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reTY9TeenpK3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02fd1bad-6c28-41d8-912b-d1dea7f27aec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# queste sono alcuni moduli di Python necessari per la gestione dei files e delle cartelle\n",
        "# drive monta il proprio spazio Google Drive e lo rende accessibile all'istanza di Python su cui sta girando questo notebook\n",
        "# Eseguendo questa cella sarà necessario autorizzare Colab ad accedere a Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "# Cambio la cartella default per comodità. In questa cartella, di cui bisogna conoscere il percorso all'interno del proprio spazio Drive,\n",
        "# verranno salvati alcuni dei files che verranno scaricati dalla rete.\n",
        "\n",
        "import os\n",
        "# os.chdir('nomedellacartelladesiderata')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2vec\n",
        "## Text8"
      ],
      "metadata": {
        "id": "ev3MGNEUru9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Questo consente di scaricare dataset e modelli preaddestrati usando il modulo gensim\n",
        "import gensim.downloader as api\n",
        "# text8 è una piccola porzione (20M di parole) da Wikipedia\n",
        "text8 = api.load('text8')\n",
        "# Word2Vec è l'oggetto che consente di addestrare il modello\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "# Questo è l'addestramento del modello vero e proprio, che viene salvato nella variabile mt8\n",
        "mt8 = Word2Vec(text8)"
      ],
      "metadata": {
        "id": "IMIXlJYDoEAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# queste sono le 20 parole più simili alla parola 'cat', secondo questo modello\n",
        "mt8.wv.most_similar('cat', topn=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "205TAnyLrsjY",
        "outputId": "3b50e7e1-09fc-49be-a913-0770da481ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('dog', 0.8496007323265076),\n",
              " ('pig', 0.8202006816864014),\n",
              " ('goat', 0.8035016059875488),\n",
              " ('bee', 0.8019393682479858),\n",
              " ('panda', 0.800677478313446),\n",
              " ('hamster', 0.7719034552574158),\n",
              " ('bird', 0.7654104828834534),\n",
              " ('blonde', 0.761848509311676),\n",
              " ('pet', 0.7596496343612671),\n",
              " ('ass', 0.757304847240448),\n",
              " ('rat', 0.7557088732719421),\n",
              " ('flower', 0.7396717071533203),\n",
              " ('eyed', 0.7377806305885315),\n",
              " ('stuffed', 0.7367633581161499),\n",
              " ('deer', 0.7358433604240417),\n",
              " ('llama', 0.7346656918525696),\n",
              " ('leopard', 0.727406919002533),\n",
              " ('rabbit', 0.7237824201583862),\n",
              " ('aloe', 0.7236571907997131),\n",
              " ('dogs', 0.7221463918685913)]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google News\n"
      ],
      "metadata": {
        "id": "svHnOKwai7Az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scarichiamo il modello word2vec addestrato con google news.\n",
        "gnews = api.load('word2vec-google-news-300')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S97huFNyTAby",
        "outputId": "6f4d74d7-a1b4-4a5c-8d5d-4179da392de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NB**: si tratta di un file piuttosto grande. SE lo si vuole salvare in una cartella Google Drive. Si può eseguire il comando 'save', eseguendo in una cella di codice questa istruzione:\n",
        "\n",
        "```python\n",
        "gnews.save('word2vec-google-news-300.model')\n",
        "```\n",
        "\n",
        "Una volta salvato, il modello si può recuperare, senza che lo si debba scaricare un'altra volta, usando questa istruzione:\n",
        "\n",
        "```python\n",
        "from gensim.models import KeyedVectors\n",
        "modello = KeyedVectors.load('word2vec-google-news-300.model')\n",
        "```"
      ],
      "metadata": {
        "id": "sXQQH9ffjqmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Questo modello ha una performance più convincente\n",
        "gnews.most_similar('cat')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7zuTZhSkwzb",
        "outputId": "6182b773-0c93-4a71-a657-9ba393e5431f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cats', 0.8099379539489746),\n",
              " ('dog', 0.760945737361908),\n",
              " ('kitten', 0.7464985251426697),\n",
              " ('feline', 0.7326234579086304),\n",
              " ('beagle', 0.7150582671165466),\n",
              " ('puppy', 0.7075453400611877),\n",
              " ('pup', 0.6934291124343872),\n",
              " ('pet', 0.6891531348228455),\n",
              " ('felines', 0.6755931973457336),\n",
              " ('chihuahua', 0.6709762215614319)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All'interno del modello, i concetti associati ai termini di una lingua, sono rappresentati come vettori\n",
        "gnews.get_vector('dog')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "paA56y6DdzCp",
        "outputId": "bde98bcb-22aa-4dcb-830f-0735d45ebb79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5.12695312e-02, -2.23388672e-02, -1.72851562e-01,  1.61132812e-01,\n",
              "       -8.44726562e-02,  5.73730469e-02,  5.85937500e-02, -8.25195312e-02,\n",
              "       -1.53808594e-02, -6.34765625e-02,  1.79687500e-01, -4.23828125e-01,\n",
              "       -2.25830078e-02, -1.66015625e-01, -2.51464844e-02,  1.07421875e-01,\n",
              "       -1.99218750e-01,  1.59179688e-01, -1.87500000e-01, -1.20117188e-01,\n",
              "        1.55273438e-01, -9.91210938e-02,  1.42578125e-01, -1.64062500e-01,\n",
              "       -8.93554688e-02,  2.00195312e-01, -1.49414062e-01,  3.20312500e-01,\n",
              "        3.28125000e-01,  2.44140625e-02, -9.71679688e-02, -8.20312500e-02,\n",
              "       -3.63769531e-02, -8.59375000e-02, -9.86328125e-02,  7.78198242e-03,\n",
              "       -1.34277344e-02,  5.27343750e-02,  1.48437500e-01,  3.33984375e-01,\n",
              "        1.66015625e-02, -2.12890625e-01, -1.50756836e-02,  5.24902344e-02,\n",
              "       -1.07421875e-01, -8.88671875e-02,  2.49023438e-01, -7.03125000e-02,\n",
              "       -1.59912109e-02,  7.56835938e-02, -7.03125000e-02,  1.19140625e-01,\n",
              "        2.29492188e-01,  1.41601562e-02,  1.15234375e-01,  7.50732422e-03,\n",
              "        2.75390625e-01, -2.44140625e-01,  2.96875000e-01,  3.49121094e-02,\n",
              "        2.42187500e-01,  1.35742188e-01,  1.42578125e-01,  1.75781250e-02,\n",
              "        2.92968750e-02, -1.21582031e-01,  2.28271484e-02, -4.76074219e-02,\n",
              "       -1.55273438e-01,  3.14331055e-03,  3.45703125e-01,  1.22558594e-01,\n",
              "       -1.95312500e-01,  8.10546875e-02, -6.83593750e-02, -1.47094727e-02,\n",
              "        2.14843750e-01, -1.21093750e-01,  1.57226562e-01, -2.07031250e-01,\n",
              "        1.36718750e-01, -1.29882812e-01,  5.29785156e-02, -2.71484375e-01,\n",
              "       -2.98828125e-01, -1.84570312e-01, -2.29492188e-01,  1.19140625e-01,\n",
              "        1.53198242e-02, -2.61718750e-01, -1.23046875e-01, -1.86767578e-02,\n",
              "       -6.49414062e-02, -8.15429688e-02,  7.86132812e-02, -3.53515625e-01,\n",
              "        5.24902344e-02, -2.45361328e-02, -5.43212891e-03, -2.08984375e-01,\n",
              "       -2.10937500e-01, -1.79687500e-01,  2.42187500e-01,  2.57812500e-01,\n",
              "        1.37695312e-01, -2.10937500e-01, -2.17285156e-02, -1.38671875e-01,\n",
              "        1.84326172e-02, -1.23901367e-02, -1.59179688e-01,  1.61132812e-01,\n",
              "        2.08007812e-01,  1.03027344e-01,  9.81445312e-02, -6.83593750e-02,\n",
              "       -8.72802734e-03, -2.89062500e-01, -2.14843750e-01, -1.14257812e-01,\n",
              "       -2.21679688e-01,  4.12597656e-02, -3.12500000e-01, -5.59082031e-02,\n",
              "       -9.76562500e-02,  5.81054688e-02, -4.05273438e-02, -1.73828125e-01,\n",
              "        1.64062500e-01, -2.53906250e-01, -1.54296875e-01, -2.31933594e-02,\n",
              "       -2.38281250e-01,  2.07519531e-02, -2.73437500e-01,  3.90625000e-03,\n",
              "        1.13769531e-01, -1.73828125e-01,  2.57812500e-01,  2.35351562e-01,\n",
              "        5.22460938e-02,  6.83593750e-02, -1.75781250e-01,  1.60156250e-01,\n",
              "       -5.98907471e-04,  5.98144531e-02, -2.11914062e-01, -5.54199219e-02,\n",
              "       -7.51953125e-02, -3.06640625e-01,  4.27734375e-01,  5.32226562e-02,\n",
              "       -2.08984375e-01, -5.71289062e-02, -2.09960938e-01,  3.29589844e-02,\n",
              "        1.05468750e-01, -1.50390625e-01, -9.37500000e-02,  1.16699219e-01,\n",
              "        6.44531250e-02,  2.80761719e-02,  2.41210938e-01, -1.25976562e-01,\n",
              "       -1.00585938e-01, -1.22680664e-02, -3.26156616e-04,  1.58691406e-02,\n",
              "        1.27929688e-01, -3.32031250e-02,  4.07714844e-02, -1.31835938e-01,\n",
              "        9.81445312e-02,  1.74804688e-01, -2.36328125e-01,  5.17578125e-02,\n",
              "        1.83593750e-01,  2.42919922e-02, -4.31640625e-01,  2.46093750e-01,\n",
              "       -3.03955078e-02, -2.47802734e-02, -1.17187500e-01,  1.61132812e-01,\n",
              "       -5.71289062e-02,  1.16577148e-02,  2.81250000e-01,  4.27734375e-01,\n",
              "        4.56542969e-02,  1.01074219e-01, -3.95507812e-02,  1.77001953e-02,\n",
              "       -8.98437500e-02,  1.35742188e-01,  2.08007812e-01,  1.88476562e-01,\n",
              "       -1.52343750e-01, -2.37304688e-01, -1.90429688e-01,  7.12890625e-02,\n",
              "       -2.46093750e-01, -2.61718750e-01, -2.34375000e-01, -1.45507812e-01,\n",
              "       -1.17187500e-02, -1.50390625e-01, -1.13281250e-01,  1.82617188e-01,\n",
              "        2.63671875e-01, -1.37695312e-01, -4.58984375e-01, -4.68750000e-02,\n",
              "       -1.26953125e-01, -4.22363281e-02, -1.66992188e-01,  1.26953125e-01,\n",
              "        2.59765625e-01, -2.44140625e-01, -2.19726562e-01, -8.69140625e-02,\n",
              "        1.59179688e-01, -3.78417969e-02,  8.97216797e-03, -2.77343750e-01,\n",
              "       -1.04980469e-01, -1.75781250e-01,  2.28515625e-01, -2.70996094e-02,\n",
              "        2.85156250e-01, -2.73437500e-01,  1.61132812e-02,  5.90820312e-02,\n",
              "       -2.39257812e-01,  1.77734375e-01, -1.34765625e-01,  1.38671875e-01,\n",
              "        3.53515625e-01,  1.22070312e-01,  1.43554688e-01,  9.22851562e-02,\n",
              "        2.29492188e-01, -3.00781250e-01, -4.88281250e-02, -1.79687500e-01,\n",
              "        2.96875000e-01,  1.75781250e-01,  4.80957031e-02, -3.38745117e-03,\n",
              "        7.91015625e-02, -2.38281250e-01, -2.31445312e-01,  1.66015625e-01,\n",
              "       -2.13867188e-01, -7.03125000e-02, -7.56835938e-02,  1.96289062e-01,\n",
              "       -1.29882812e-01, -1.05957031e-01, -3.53515625e-01, -1.16699219e-01,\n",
              "       -5.10253906e-02,  3.39355469e-02, -1.43554688e-01, -3.90625000e-03,\n",
              "        1.73828125e-01, -9.96093750e-02, -1.66015625e-01, -8.54492188e-02,\n",
              "       -3.82812500e-01,  5.90820312e-02, -6.22558594e-02,  8.83789062e-02,\n",
              "       -8.88671875e-02,  3.28125000e-01,  6.83593750e-02, -1.91406250e-01,\n",
              "       -8.35418701e-04,  1.04003906e-01,  1.52343750e-01, -1.53350830e-03,\n",
              "        4.16015625e-01, -3.32031250e-02,  1.49414062e-01,  2.42187500e-01,\n",
              "       -1.76757812e-01, -4.93164062e-02, -1.24511719e-01,  1.25976562e-01,\n",
              "        1.74804688e-01,  2.81250000e-01, -1.80664062e-01,  1.03027344e-01,\n",
              "       -2.75390625e-01,  2.61718750e-01,  2.46093750e-01, -4.71191406e-02,\n",
              "        6.25000000e-02,  4.16015625e-01, -3.55468750e-01,  2.22656250e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A questo punto, una volta ottenuto il modello, si possono fare varie operazione, tra cui quelle delle analogie\n",
        "gnews.most_similar(positive=['king', 'woman'], negative = ['man'], topn=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfiowzO3TNPG",
        "outputId": "cc7dc35e-4ec9-4b66-dfc3-bffae4ceae07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7118193507194519),\n",
              " ('monarch', 0.6189674139022827),\n",
              " ('princess', 0.5902431011199951),\n",
              " ('crown_prince', 0.5499460697174072),\n",
              " ('prince', 0.5377321839332581),\n",
              " ('kings', 0.5236844420433044),\n",
              " ('Queen_Consort', 0.5235945582389832),\n",
              " ('queens', 0.5181134343147278),\n",
              " ('sultan', 0.5098593831062317),\n",
              " ('monarchy', 0.5087411999702454),\n",
              " ('royal_palace', 0.5087166428565979),\n",
              " ('throne', 0.5005807876586914),\n",
              " ('royal', 0.493820458650589),\n",
              " ('Princess_Sikhanyiso', 0.4936617612838745),\n",
              " ('ruler', 0.4909275770187378),\n",
              " ('empress', 0.4887814223766327),\n",
              " ('Prince_Paras', 0.4832945168018341),\n",
              " ('princes', 0.4810815751552582),\n",
              " ('King_Ahasuerus', 0.47894206643104553),\n",
              " ('very_pampered_McElhatton', 0.47636350989341736)]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Alia\n"
      ],
      "metadata": {
        "id": "lk4HlkS1i9t-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modello per l'italiano\n",
        "Possiamo creare un nostro spazio semantico a partire da testi in italiano. Per farlo basta usare del testo liberamente accessibile (useremo Wikipedia via un modulo di Python che si chiama `plainstream`) e il modulo `gensim` per addestrare il modello.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EwK2M-U0shiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# È necessario separare il testo in parole, cioè tokenizzare.\n",
        "from nltk import word_tokenize, download\n",
        "download('punkt')\n",
        "# È anche necessario installare plainstream e per farlo bisogna installare da un repository github\n",
        "!pip install git+https://github.com/lucaducceschi/plainstream.git\n",
        "import plainstream"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckhBweB3lpS_",
        "outputId": "33f82cb3-9437-4b51-e5fa-42748a3c515b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/lucaducceschi/plainstream.git\n",
            "  Cloning https://github.com/lucaducceschi/plainstream.git to /tmp/pip-req-build-cjb6gfql\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/lucaducceschi/plainstream.git /tmp/pip-req-build-cjb6gfql\n",
            "  Resolved https://github.com/lucaducceschi/plainstream.git to commit 229b08d3f6065aa2c02a47fb6ed113eebac15097\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from plainstream==0.1.0) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->plainstream==0.1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->plainstream==0.1.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->plainstream==0.1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->plainstream==0.1.0) (2024.2.2)\n",
            "Building wheels for collected packages: plainstream\n",
            "  Building wheel for plainstream (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for plainstream: filename=plainstream-0.1.0-py3-none-any.whl size=11205 sha256=edf6068f94c07693e699cca34c21459f45b0be922e31e0d37266bae590d7acae\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-15chpwci/wheels/9e/bf/1c/486573bbf492caa682a5a0578cfca368d524c3c1f645ff1c09\n",
            "Successfully built plainstream\n",
            "Installing collected packages: plainstream\n",
            "Successfully installed plainstream-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prendiamo del testo da wikipedia (in questo intorno alle 2M parole. Basta modificare il parametro max_words per avere quantità diverse.)\n",
        "# Assegnare ad una variabile tutto il testo di wikipedia non è strategia particolarmente ottimale, ma finché non si usano gb di spazio,\n",
        "# il processo non dovrebbe dare problemi.\n",
        "\n",
        "# Basta incrementare il numero di parole prelevate da wikipeida, settando max_words=100000000, ad esempio, per ottenere uno spazio semantico di qualità maggiore.\n",
        "wikit =[article for article in plainstream.get_text(\"it\", max_words=2000000, tokenize=True)]"
      ],
      "metadata": {
        "id": "6G1IwqmisCT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Questo addestra il modello\n",
        "modelit= Word2Vec(wikit)"
      ],
      "metadata": {
        "id": "DzCtr_j36xcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelit.wv.most_similar(positive = ['re', 'donna'], negative = ['uomo'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT1FeaAqAVTi",
        "outputId": "4f36d470-4059-4b30-e0a1-394090b0acca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('moglie', 0.7632821798324585),\n",
              " ('famiglia', 0.7491347193717957),\n",
              " ('battaglia', 0.7433005571365356),\n",
              " ('figlia', 0.7411913871765137),\n",
              " ('dinastia', 0.7341787219047546),\n",
              " ('tappa', 0.7341780066490173),\n",
              " ('vittoria', 0.7307442426681519),\n",
              " ('madre', 0.7267773747444153),\n",
              " ('Roma', 0.7245209217071533),\n",
              " ('Repubblica', 0.7225853204727173)]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ]
}